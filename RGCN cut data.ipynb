{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocessing_okved import fix_okved\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Задача 1\n",
    "Агрегируем связи с более низких уровней на более высокие, создаем \"укороченный\" граф, решает link prediction, тестируем\n",
    "\n",
    "## Версия 1. Стрижка дерева кодов ОКВЭД\n",
    "Просто заменяем те коды, ??**.**??**.**\\* на ??**.**??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Аггрегирование нижних уровней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "2637"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okved_graph = pd.read_pickle('../data/graph/okved_graph.pickle')\n",
    "okved_data = pd.read_csv('../data/okved2/okved_2014_w_sections.csv', index_col=0)\n",
    "okved_graph.edges()[1].unique().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "7    1184\n8     617\n5     488\n4     259\n2      88\nName: native_code, dtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okved_data['native_code'].map(len).value_counts()  # Укоротим граф до 4 знаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "5    1840\n4     701\n2      95\n1       1\ndtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Словари id-шники - коды и коды - id-шники\n",
    "id_to_code = okved_data['native_code'].to_dict()\n",
    "id_to_code[0] = '0'\n",
    "code_to_id = {v: u for u, v in id_to_code.items()}\n",
    "\n",
    "# Обрезанные до максимум 1 точки коды\n",
    "new_id_to_code = {}\n",
    "for _id, code in id_to_code.items():\n",
    "    new_id_to_code[_id] = fix_okved(code[:5])\n",
    "\n",
    "pd.Series(new_id_to_code).map(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def replace_code(code_id: int) -> int:\n",
    "    \"\"\"\n",
    "    Меняет код на родительский или оставляет таким же. Коды родительские те, которые с 0 или 1 точкой\n",
    "    \"\"\"\n",
    "    code_id = int(code_id)\n",
    "    native_code = new_id_to_code[code_id]\n",
    "\n",
    "    return code_to_id[native_code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([   3,    3,    3,  ..., 2614, 2615, 2616])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okved_graph.edges()[0].apply_(replace_code)\n",
    "okved_graph.edges()[1].apply_(replace_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "836"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okved_graph.edges()[1].unique().__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Применим RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.nn as gnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from negative_sampler import NegativeSamplerRel\n",
    "\n",
    "\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, n_hidden, n_classes, n_layers, activation, dropout, n_rels):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_classes = n_classes\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        if n_layers > 1:\n",
    "            self.layers.append(gnn.RelGraphConv(in_feats, n_hidden, num_rels=n_rels))\n",
    "            for i in range(1, n_layers - 1):\n",
    "                self.layers.append(gnn.RelGraphConv(n_hidden, n_hidden, num_rels=n_rels))\n",
    "\n",
    "            self.layers.append(gnn.RelGraphConv(n_hidden, n_classes, num_rels=n_rels))\n",
    "        else:\n",
    "            self.layers.append(gnn.RelGraphConv(in_feats, n_classes, num_rels=n_rels))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        h = x\n",
    "        edge_types = g.edata['type']\n",
    "        norm = g.edata['norm'].view(-1, 1)\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            h = layer(g, h, edge_types, norm).to(device)\n",
    "            if l != len(self.layers) - 1:\n",
    "                h = self.activation(h)\n",
    "                h = self.dropout(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, rgcn, n_rels, reg_param=0.01):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        rgcn : RGCN\n",
    "            Модель графовой нейронной сети\n",
    "        n_rels : int\n",
    "\n",
    "        reg_param : float\n",
    "            Параметр регуляризации\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.rgcn = rgcn\n",
    "        self.reg_param = reg_param\n",
    "        self.w_relation = nn.Parameter(torch.Tensor(n_rels, self.rgcn.n_classes))\n",
    "        nn.init.xavier_uniform_(self.w_relation, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : dgl.DGLHeteroGraph\n",
    "            граф кодов ОКВЭД\n",
    "        x : torch.Tensor\n",
    "            эмбеддинги описаний\n",
    "        \"\"\"\n",
    "        return F.dropout(self.rgcn(g, x), p=0.2)\n",
    "\n",
    "    def calc_score(self, embedding, graph):\n",
    "        \"\"\"\n",
    "        Возвращает DistMult. https://pykeen.readthedocs.io/en/stable/api/pykeen.models.DistMult.html\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        embedding : torch.Tensor\n",
    "            эмбеддинг узлов\n",
    "        graph : dgl.DGLHeteroGraph\n",
    "            граф кодов ОКВЭД\n",
    "        \"\"\"\n",
    "        # DistMult\n",
    "        source, target, num_relation = graph.edges(form='all')\n",
    "        edge_types = graph.edata['type'][num_relation]  # edge type\n",
    "        s = embedding[source]\n",
    "        r = self.w_relation[edge_types]\n",
    "        o = embedding[target]\n",
    "        score = torch.sum(s * r * o, dim=1)\n",
    "        return score\n",
    "\n",
    "    def regularization_loss(self, embedding):\n",
    "        \"\"\"\n",
    "        Возвращает l2 регуляризацию в квадрате\n",
    "         \n",
    "        Parameters\n",
    "        ----------\n",
    "        embedding : torch.Tensor\n",
    "            эмбеддинг узлов\n",
    "        \"\"\"\n",
    "        return torch.mean(embedding.pow(2)) + torch.mean(self.w_relation.pow(2))\n",
    "\n",
    "    def get_loss(self, embedding, pos_graph, neg_graph):\n",
    "        \"\"\"\n",
    "        Вычисляет полную ошибку, по положительным и отрицательным примерам\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        embedding : torch.Tensor\n",
    "            эмбеддинг узлов\n",
    "        pos_graph : dgl.DGLHeteroGraph\n",
    "            граф кодов ОКВЭД\n",
    "        neg_graph : dgl.DGLHeteroGraph\n",
    "            граф случайно созданных связей между кодами ОКВЭД\n",
    "\n",
    "        \"\"\"\n",
    "        pos_score = self.calc_score(embedding, pos_graph)\n",
    "        neg_score = self.calc_score(embedding, neg_graph)\n",
    "        score = torch.cat([pos_score, neg_score])\n",
    "        label = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)]).long()\n",
    "        predict_loss = F.binary_cross_entropy_with_logits(score, label.float())\n",
    "\n",
    "        reg_loss = self.regularization_loss(embedding)\n",
    "        return predict_loss + self.reg_param * reg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_negs = 1\n",
    "neg_share = False\n",
    "device = torch.device('cuda')\n",
    "num_hidden = 256\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "lr = 0.001\n",
    "num_epochs = 20\n",
    "best_loss = 1000000\n",
    "last_improvement = 0\n",
    "require_improvements = 50\n",
    "best_state = None\n",
    "n_rels = 3\n",
    "reg_param = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g = okved_graph.clone().to(device)\n",
    "\n",
    "nfeat = g.ndata['feat'].float().to(device)\n",
    "in_feats = nfeat.shape[1]\n",
    "n_edges = g.num_edges()\n",
    "\n",
    "bsize = 131072\n",
    "n_batch = n_edges // bsize  # Размер батча\n",
    "\n",
    "rgcn = RGCN(in_feats, num_hidden, num_hidden, num_layers, F.relu, dropout, n_rels)\n",
    "model = LinkPredictor(rgcn, n_rels=n_rels, reg_param=reg_param).to(device)\n",
    "sampler = NegativeSamplerRel(k=num_negs)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "% % time\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    for i in range(0, n_edges - 1, bsize):\n",
    "        g_batch = g.edge_subgraph(list(range(i, min(i + bsize, n_edges))))\n",
    "        nfeat_batch = g_batch.ndata['feat'].float().to(device)\n",
    "        neg_graph = sampler(g_batch).to(device)\n",
    "\n",
    "        # Compute loss and prediction\n",
    "        pred = model(g_batch, nfeat_batch)\n",
    "        loss = model.get_loss(pred, g_batch, neg_graph)\n",
    "        epoch_loss.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # clip gradients\n",
    "        optimizer.step()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    loss = np.mean(epoch_loss)\n",
    "    print(f'Epoch : {epoch:02d}  |  Loss : {loss:.4f}')\n",
    "\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        last_improvement = 0\n",
    "        best_state = model.state_dict()\n",
    "    else:\n",
    "        last_improvement += 1\n",
    "\n",
    "    if last_improvement > require_improvements:\n",
    "        print(f\"No improvement found during the {require_improvements} last iterations, stopping optimization.\")\n",
    "        model.load_state_dict(best_state)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "embeddings_bert = np.load('../data/okved2/okved_embeddings.npy')\n",
    "okved_consumption = pd.read_csv('../data/stats/okved_consumption.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "embeddings_model = model(g, nfeat).detach().cpu().numpy()[1:]\n",
    "\n",
    "embeddings_model_2d = TSNE(n_components=2, init='random').fit_transform(embeddings_model)\n",
    "embeddings_bert_2d = TSNE(n_components=2, init='random').fit_transform(embeddings_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "sections = okved_data['section_id'].values\n",
    "fig = px.scatter(x=embeddings_model_2d[:, 0], y=embeddings_model_2d[:, 1], color=sections,\n",
    "                 title='<b>TSNE embeddings. OUR MODEL</b>')\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(x=embeddings_bert_2d[:, 0], y=embeddings_bert_2d[:, 1], color=sections,\n",
    "                 title='<b>TSNE embeddings. BERT</b>')\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prov_indices = okved_consumption['okved_provider'].map(fix_okved).map(code_to_id)\n",
    "cons_indices = okved_consumption['okved_consumer'].map(fix_okved).map(code_to_id)\n",
    "\n",
    "X_bert = np.column_stack((embeddings_bert[prov_indices], embeddings_bert[cons_indices]))\n",
    "X_bert = StandardScaler().fit_transform(X_bert)\n",
    "\n",
    "X_model = np.column_stack((embeddings_model[prov_indices], embeddings_model[cons_indices]))\n",
    "X_model = StandardScaler().fit_transform(X_model)\n",
    "\n",
    "y = okved_consumption['normalized_consumption']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Линейная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X_model, y)\n",
    "score = model.score(X_model, y)\n",
    "print(f'Модель: {score: 0.4f}')\n",
    "\n",
    "model = LinearRegression().fit(X_bert, y)\n",
    "score = model.score(X_bert, y)\n",
    "print(f'Берт: {score: 0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Многослойный перцептрон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MLPRegressorTorch(nn.Module):\n",
    "    def __init__(self, input_dim: int, layer_dims: tuple[int, ...] = (100,), activation=nn.ReLU()):\n",
    "        super(MLPRegressor_torch, self).__init__()\n",
    "        self.layers = [nn.Linear(input_dim, layer_dims[0]), activation]\n",
    "        for i in range(1, len(layer_dims) - 1):\n",
    "            self.layers.append(nn.Linear(layer_dims[i], layer_dims[i + 1]))\n",
    "            self.layers.append(activation)\n",
    "        else:\n",
    "            self.layers.append(nn.Linear(layer_dims[-1], 1))\n",
    "            self.layers.append(activation)\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def r2_score(self, x, y):\n",
    "        from sklearn.metrics import r2_score\n",
    "        y_pred = self.forward(x).flatten()\n",
    "        return r2_score(y.detach().cpu().numpy(), y_pred.detach().cpu().numpy())\n",
    "\n",
    "    def get_loss(self, x, y):\n",
    "        x = self.forward(x).flatten()\n",
    "        return self.criterion(y, x)\n",
    "\n",
    "    def fit(self, x, y, val: list = None, epochs: int = 1, verbose=False):\n",
    "        self.train()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.0001)\n",
    "        show_epochs = list(np.unique(np.geomspace(1, epochs, 15, dtype=int)))\n",
    "        last_improvement = 0\n",
    "        best_val_loss = 10 ** 10\n",
    "\n",
    "        for i in range(epochs):\n",
    "            loss = self.get_loss(x, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Валидация\n",
    "            if val is not None:\n",
    "                with torch.no_grad():\n",
    "                    val_loss = self.get_loss(val[0], val[1]).item()\n",
    "\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    last_improvement = 0\n",
    "                    best_state = self.state_dict()\n",
    "                else:\n",
    "                    last_improvement += 1\n",
    "\n",
    "            # Печать\n",
    "            if verbose:\n",
    "                if i in show_epochs + [epochs - 1]:\n",
    "                    with torch.no_grad():\n",
    "                        if val is not None:\n",
    "                            val_loss = self.get_loss(val[0], val[1]).item()\n",
    "                            print(f'epoch {i + 1: 6d}  :  loss : {loss.item(): .5f} | val loss : {val_loss: .5f}')\n",
    "                        else:\n",
    "                            print(f'epoch {i + 1: 6d}  :  loss : {loss.item(): .5f}')\n",
    "        else:\n",
    "            if last_improvement > 0:\n",
    "                self.load_state_dict(best_state)\n",
    "\n",
    "\n",
    "X_model_th = torch.FloatTensor(X_model).to(device)\n",
    "X_bert_th = torch.FloatTensor(X_bert).to(device)\n",
    "y_th = torch.FloatTensor(y.values).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG VAL model R2: -0.0375\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=6)\n",
    "\n",
    "model = MLPRegressor_torch(X_model.shape[1], (100,)).to(device)\n",
    "val_scores = []\n",
    "for train, val in kf.split(X_model_th):\n",
    "    model.fit(X_model_th[train], y_th[train], val=[X_model_th[val], y_th[val]], epochs=200)\n",
    "    val_scores.append(model.r2_score(X_model_th[val], y_th[val]))\n",
    "\n",
    "print(f'AVG VAL model R2: {np.mean(val_scores): 0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG VAL bert R2:  0.0254\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor_torch(X_bert.shape[1], (100,)).to(device)\n",
    "val_scores = []\n",
    "for train, val in kf.split(X_bert_th):\n",
    "    model.fit(X_bert_th[train], y_th[train], val=[X_bert_th[val], y_th[val]], epochs=200)\n",
    "    val_scores.append(model.r2_score(X_bert_th[val], y_th[val]))\n",
    "\n",
    "print(f'AVG VAL bert R2: {np.mean(val_scores): 0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:16<00:00,  3.82s/it]\n"
     ]
    }
   ],
   "source": [
    "bert_scores = []\n",
    "model_scores = []\n",
    "\n",
    "kf = KFold(n_splits=6)\n",
    "\n",
    "for i in tqdm(range(20)):\n",
    "\n",
    "    model = MLPRegressor_torch(X_model.shape[1], (100,)).to(device)  # эмбеддинги нашей моделью\n",
    "    val_scores = []\n",
    "    # Обучаем модель с помощью кросс валидации\n",
    "    for train, val in kf.split(X_model_th):\n",
    "        # Во время обучения контролируем переобучение с помощью валидационных данных\n",
    "        model.fit(X_model_th[train], y_th[train],\n",
    "                  val=[X_model_th[val], y_th[val]],\n",
    "                  epochs=200)\n",
    "        val_scores.append(model.r2_score(X_model_th[val], y_th[val]))\n",
    "\n",
    "    model_scores.append(np.mean(val_scores))\n",
    "\n",
    "    model = MLPRegressor_torch(X_bert.shape[1], (100,)).to(device)\n",
    "    val_scores = []\n",
    "\n",
    "    for train, val in kf.split(X_bert_th):\n",
    "        model.fit(X_bert_th[train], y_th[train],\n",
    "                  val=[X_bert_th[val], y_th[val]],\n",
    "                  epochs=200)\n",
    "\n",
    "        val_scores.append(model.r2_score(X_bert_th[val], y_th[val]))\n",
    "\n",
    "    bert_scores.append(np.mean(val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: 0.02 ± 0.08\n",
      "Берт: 0.14 ± 0.09\n"
     ]
    }
   ],
   "source": [
    "print(f'Модель: {np.mean(model_scores):.2f} ± {np.std(model_scores):.2f}')\n",
    "print(f'Берт: {np.mean(bert_scores):.2f} ± {np.std(bert_scores):.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}